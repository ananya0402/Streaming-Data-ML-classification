{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Streaming application using Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SparkSession is created using a SparkConf object, which would use two local cores with a proper application name, and use UTC as the timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 pyspark-shell'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Assignment 2B\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. From the Kafka producers in Task 1.1 and 1.2, ingest the streaming data into Spark Streaming for both process and memory activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Streaming_Linux_process\"\n",
    "process_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "  .option(\"subscribe\", topic) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Streaming_Linux_memory\"\n",
    "memory_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "  .option(\"subscribe\", topic) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Then the streaming data format should be transformed into the proper formats following the metadata file schema for both process and memory, similar to assignment 2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_schema = ArrayType(StructType([\n",
    "    StructField(\"sequence\", StringType(),True),\n",
    "    StructField(\"machine\", StringType(),True),\n",
    "    StructField(\"PID\", StringType(),True),\n",
    "    StructField(\"MINFLT\", StringType(),True),\n",
    "    StructField(\"MAJFLT\", StringType(),True),\n",
    "    StructField(\"VSTEXT\", StringType(),True),\n",
    "    StructField(\"VSIZE\", StringType(),True),\n",
    "    StructField(\"RSIZE\", StringType(),True),\n",
    "    StructField(\"VGROW\", StringType(),True),\n",
    "    StructField(\"RGROW\", StringType(),True),\n",
    "    StructField(\"MEM\", StringType(),True),\n",
    "    StructField(\"CMD\", StringType(),True),\n",
    "    StructField(\"ts\", StringType(),True)\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling JSON format array\n",
    "memory_df = memory_df.select(F.from_json(F.col(\"value\").cast(\"string\"), memory_schema).alias('parsed_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parsed_value: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- sequence: string (nullable = true)\n",
      " |    |    |-- machine: string (nullable = true)\n",
      " |    |    |-- PID: string (nullable = true)\n",
      " |    |    |-- MINFLT: string (nullable = true)\n",
      " |    |    |-- MAJFLT: string (nullable = true)\n",
      " |    |    |-- VSTEXT: string (nullable = true)\n",
      " |    |    |-- VSIZE: string (nullable = true)\n",
      " |    |    |-- RSIZE: string (nullable = true)\n",
      " |    |    |-- VGROW: string (nullable = true)\n",
      " |    |    |-- RGROW: string (nullable = true)\n",
      " |    |    |-- MEM: string (nullable = true)\n",
      " |    |    |-- CMD: string (nullable = true)\n",
      " |    |    |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_df = memory_df.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unnested_value: struct (nullable = true)\n",
      " |    |-- sequence: string (nullable = true)\n",
      " |    |-- machine: string (nullable = true)\n",
      " |    |-- PID: string (nullable = true)\n",
      " |    |-- MINFLT: string (nullable = true)\n",
      " |    |-- MAJFLT: string (nullable = true)\n",
      " |    |-- VSTEXT: string (nullable = true)\n",
      " |    |-- VSIZE: string (nullable = true)\n",
      " |    |-- RSIZE: string (nullable = true)\n",
      " |    |-- VGROW: string (nullable = true)\n",
      " |    |-- RGROW: string (nullable = true)\n",
      " |    |-- MEM: string (nullable = true)\n",
      " |    |-- CMD: string (nullable = true)\n",
      " |    |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the names of the columns accordingly\n",
    "memory_df_formatted = memory_df.select(\n",
    "                    F.col(\"unnested_value.sequence\").alias(\"sequence\"),\n",
    "                    F.col(\"unnested_value.machine\").alias(\"machine\"),\n",
    "                    F.col(\"unnested_value.PID\").alias(\"PID\"),\n",
    "                    F.col(\"unnested_value.MINFLT\").alias(\"MINFLT\"),\n",
    "                    F.col(\"unnested_value.MAJFLT\").alias(\"MAJFLT\"),\n",
    "                    F.col(\"unnested_value.VSTEXT\").alias(\"VSTEXT\"),\n",
    "                    F.col(\"unnested_value.VSIZE\").alias(\"VSIZE\"),\n",
    "                    F.col(\"unnested_value.RSIZE\").alias(\"RSIZE\"),\n",
    "                    F.col(\"unnested_value.VGROW\").alias(\"VGROW\"),\n",
    "                    F.col(\"unnested_value.RGROW\").alias(\"RGROW\"),\n",
    "                    F.col(\"unnested_value.MEM\").alias(\"MEM\"),\n",
    "                    F.col(\"unnested_value.CMD\").alias(\"CMD\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"ts\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: string (nullable = true)\n",
      " |-- machine: string (nullable = true)\n",
      " |-- PID: string (nullable = true)\n",
      " |-- MINFLT: string (nullable = true)\n",
      " |-- MAJFLT: string (nullable = true)\n",
      " |-- VSTEXT: string (nullable = true)\n",
      " |-- VSIZE: string (nullable = true)\n",
      " |-- RSIZE: string (nullable = true)\n",
      " |-- VGROW: string (nullable = true)\n",
      " |-- RGROW: string (nullable = true)\n",
      " |-- MEM: string (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = memory_df_formatted \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning and transforming the columns into proper format\n",
    "memory_df_formatted = memory_df_formatted.withColumn('MINFLT', regexp_replace('MINFLT', 'K', '000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('MAJFLT', regexp_replace('MAJFLT', 'M', '00000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('VSTEXT', regexp_replace('VSTEXT', 'K', '000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('RSIZE', regexp_replace('RSIZE', 'K', '000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('RSIZE', regexp_replace('RSIZE', 'M', '00000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('VGROW', regexp_replace('VGROW', 'K', '000'))\n",
    "memory_df_formatted = memory_df_formatted.withColumn('RGROW', regexp_replace('RGROW', 'K', '000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: string (nullable = true)\n",
      " |-- machine: string (nullable = true)\n",
      " |-- PID: string (nullable = true)\n",
      " |-- MINFLT: string (nullable = true)\n",
      " |-- MAJFLT: string (nullable = true)\n",
      " |-- VSTEXT: string (nullable = true)\n",
      " |-- VSIZE: string (nullable = true)\n",
      " |-- RSIZE: string (nullable = true)\n",
      " |-- VGROW: string (nullable = true)\n",
      " |-- RGROW: string (nullable = true)\n",
      " |-- MEM: string (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast the columns to their proper datatypes\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"sequence\", memory_df_formatted[\"sequence\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"machine\", memory_df_formatted[\"machine\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"PID\", memory_df_formatted[\"PID\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"MINFLT\", memory_df_formatted[\"MINFLT\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"MAJFLT\", memory_df_formatted[\"MAJFLT\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"VSTEXT\", memory_df_formatted[\"VSTEXT\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"VSIZE\", memory_df_formatted[\"VSIZE\"].cast(DoubleType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"RSIZE\", memory_df_formatted[\"RSIZE\"].cast(DoubleType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"RGROW\", memory_df_formatted[\"RGROW\"].cast(DoubleType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"RGROW\", memory_df_formatted[\"MEM\"].cast(DoubleType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"ts\", memory_df_formatted[\"ts\"].cast(IntegerType()))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"MEM\", memory_df_formatted[\"MEM\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_df_formatted = memory_df_formatted.withColumn('VGROW',regexp_replace('VGROW',' ',''))\n",
    "memory_df_formatted = memory_df_formatted.withColumn(\"VGROW\", memory_df_formatted[\"VGROW\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: integer (nullable = true)\n",
      " |-- machine: integer (nullable = true)\n",
      " |-- PID: integer (nullable = true)\n",
      " |-- MINFLT: integer (nullable = true)\n",
      " |-- MAJFLT: integer (nullable = true)\n",
      " |-- VSTEXT: integer (nullable = true)\n",
      " |-- VSIZE: double (nullable = true)\n",
      " |-- RSIZE: double (nullable = true)\n",
      " |-- VGROW: double (nullable = true)\n",
      " |-- RGROW: double (nullable = true)\n",
      " |-- MEM: integer (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the schema for the structured datastream received\n",
    "schema = ArrayType(StructType([\n",
    "    StructField(\"sequence\", StringType(),True),\n",
    "    StructField(\"machine\", StringType(),True),\n",
    "    StructField(\"PID\", StringType(),True),\n",
    "    StructField(\"TRUN\", StringType(),True),\n",
    "    StructField(\"TSLPI\", StringType(),True),\n",
    "    StructField(\"TSLPU\", StringType(),True),\n",
    "    StructField(\"POLI\", StringType(),True),\n",
    "    StructField(\"NICE\", StringType(),True),\n",
    "    StructField(\"PRI\", StringType(),True),\n",
    "    StructField(\"RTPR\", StringType(),True),\n",
    "    StructField(\"CPUNR\", StringType(),True),\n",
    "    StructField(\"Status\", StringType(),True),\n",
    "    StructField(\"EXC\", StringType(),True),\n",
    "    StructField(\"State\", StringType(),True),\n",
    "    StructField(\"CPU\", StringType(),True),\n",
    "    StructField(\"CMD\", StringType(),True),\n",
    "    StructField(\"ts\", StringType(),True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling JSON format array\n",
    "process_df = process_df.select(F.from_json(F.col(\"value\").cast(\"string\"), schema).alias('parsed_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parsed_value: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- sequence: string (nullable = true)\n",
      " |    |    |-- machine: string (nullable = true)\n",
      " |    |    |-- PID: string (nullable = true)\n",
      " |    |    |-- TRUN: string (nullable = true)\n",
      " |    |    |-- TSLPI: string (nullable = true)\n",
      " |    |    |-- TSLPU: string (nullable = true)\n",
      " |    |    |-- POLI: string (nullable = true)\n",
      " |    |    |-- NICE: string (nullable = true)\n",
      " |    |    |-- PRI: string (nullable = true)\n",
      " |    |    |-- RTPR: string (nullable = true)\n",
      " |    |    |-- CPUNR: string (nullable = true)\n",
      " |    |    |-- Status: string (nullable = true)\n",
      " |    |    |-- EXC: string (nullable = true)\n",
      " |    |    |-- State: string (nullable = true)\n",
      " |    |    |-- CPU: string (nullable = true)\n",
      " |    |    |-- CMD: string (nullable = true)\n",
      " |    |    |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df = process_df.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unnested_value: struct (nullable = true)\n",
      " |    |-- sequence: string (nullable = true)\n",
      " |    |-- machine: string (nullable = true)\n",
      " |    |-- PID: string (nullable = true)\n",
      " |    |-- TRUN: string (nullable = true)\n",
      " |    |-- TSLPI: string (nullable = true)\n",
      " |    |-- TSLPU: string (nullable = true)\n",
      " |    |-- POLI: string (nullable = true)\n",
      " |    |-- NICE: string (nullable = true)\n",
      " |    |-- PRI: string (nullable = true)\n",
      " |    |-- RTPR: string (nullable = true)\n",
      " |    |-- CPUNR: string (nullable = true)\n",
      " |    |-- Status: string (nullable = true)\n",
      " |    |-- EXC: string (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      " |    |-- CPU: string (nullable = true)\n",
      " |    |-- CMD: string (nullable = true)\n",
      " |    |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the names of the columns accordingly\n",
    "process_df_formatted = process_df.select(\n",
    "                    F.col(\"unnested_value.sequence\").alias(\"sequence\"),\n",
    "                    F.col(\"unnested_value.machine\").alias(\"machine\"),\n",
    "                    F.col(\"unnested_value.PID\").alias(\"PID\"),\n",
    "                    F.col(\"unnested_value.TRUN\").alias(\"TRUN\"),\n",
    "                    F.col(\"unnested_value.TSLPI\").alias(\"TSLPI\"),\n",
    "                    F.col(\"unnested_value.TSLPU\").alias(\"TSLPU\"),\n",
    "                    F.col(\"unnested_value.POLI\").alias(\"POLI\"),\n",
    "                    F.col(\"unnested_value.NICE\").alias(\"NICE\"),\n",
    "                    F.col(\"unnested_value.PRI\").alias(\"PRI\"),\n",
    "                    F.col(\"unnested_value.RTPR\").alias(\"RTPR\"),\n",
    "                    F.col(\"unnested_value.CPUNR\").alias(\"CPUNR\"),\n",
    "                    F.col(\"unnested_value.Status\").alias(\"Status\"),\n",
    "                    F.col(\"unnested_value.EXC\").alias(\"EXC\"),\n",
    "                    F.col(\"unnested_value.State\").alias(\"State\"),\n",
    "                    F.col(\"unnested_value.CPU\").alias(\"CPU\"),\n",
    "                    F.col(\"unnested_value.CMD\").alias(\"CMD\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"ts\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: string (nullable = true)\n",
      " |-- machine: string (nullable = true)\n",
      " |-- PID: string (nullable = true)\n",
      " |-- TRUN: string (nullable = true)\n",
      " |-- TSLPI: string (nullable = true)\n",
      " |-- TSLPU: string (nullable = true)\n",
      " |-- POLI: string (nullable = true)\n",
      " |-- NICE: string (nullable = true)\n",
      " |-- PRI: string (nullable = true)\n",
      " |-- RTPR: string (nullable = true)\n",
      " |-- CPUNR: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- EXC: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- CPU: string (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_df_formatted \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast the columns to their proper datatypes\n",
    "process_df_formatted = process_df_formatted.withColumn(\"sequence\", process_df_formatted[\"sequence\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"machine\", process_df_formatted[\"machine\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"PID\", process_df_formatted[\"PID\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"TRUN\", process_df_formatted[\"TRUN\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"TSLPI\", process_df_formatted[\"TSLPI\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"TSLPU\", process_df_formatted[\"TSLPU\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"NICE\", process_df_formatted[\"NICE\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"PRI\", process_df_formatted[\"PRI\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"RTPR\", process_df_formatted[\"RTPR\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"CPUNR\", process_df_formatted[\"CPUNR\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"EXC\", process_df_formatted[\"EXC\"].cast(IntegerType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"CPU\", process_df_formatted[\"CPU\"].cast(DoubleType()))\n",
    "process_df_formatted = process_df_formatted.withColumn(\"ts\", process_df_formatted[\"ts\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE value is restored based on the PRI values\n",
    "process_df_formatted = process_df_formatted.withColumn(\"NICE\", F.when(F.col(\"PRI\")==0, 0).otherwise(F.col(\"PRI\")-120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_df_formatted \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: integer (nullable = true)\n",
      " |-- machine: integer (nullable = true)\n",
      " |-- PID: integer (nullable = true)\n",
      " |-- TRUN: integer (nullable = true)\n",
      " |-- TSLPI: integer (nullable = true)\n",
      " |-- TSLPU: integer (nullable = true)\n",
      " |-- POLI: string (nullable = true)\n",
      " |-- NICE: integer (nullable = true)\n",
      " |-- PRI: integer (nullable = true)\n",
      " |-- RTPR: integer (nullable = true)\n",
      " |-- CPUNR: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- EXC: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- CPU: double (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For process and memory, respectively, create a new column “CMD_PID” concatenating “CMD” and “PID” columns, and a new column “event_time” as timestamp format based on the unix time in “ts” column (5%)\n",
    "   ### - Allow 20-second tolerance for possible data delay on “event_time” using watermarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate CMD and PID and make a new column CMD_PID\n",
    "process_df_formatted = process_df_formatted.withColumn('CMD_PID', F.concat(F.col('CMD'),F.lit('_'), F.col('PID')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#“event_time” as timestamp format based on the unix time in “ts” column is created\n",
    "process_df_formatted=process_df_formatted.withColumn('event_time', F.current_timestamp()).withWatermark(\"event_time\", \"20 seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: integer (nullable = true)\n",
      " |-- machine: integer (nullable = true)\n",
      " |-- PID: integer (nullable = true)\n",
      " |-- TRUN: integer (nullable = true)\n",
      " |-- TSLPI: integer (nullable = true)\n",
      " |-- TSLPU: integer (nullable = true)\n",
      " |-- POLI: string (nullable = true)\n",
      " |-- NICE: integer (nullable = true)\n",
      " |-- PRI: integer (nullable = true)\n",
      " |-- RTPR: integer (nullable = true)\n",
      " |-- CPUNR: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- EXC: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- CPU: double (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      " |-- CMD_PID: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate CMD and PID and make a new column CMD_PID\n",
    "memory_df_formatted = memory_df_formatted.withColumn('CMD_PID', F.concat(F.col('CMD'),F.lit('_'), F.col('PID')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#“event_time” as timestamp format based on the unix time in “ts” column is created\n",
    "memory_df_formatted=memory_df_formatted.withColumn('event_time', F.current_timestamp()).withWatermark(\"event_time\", \"20 seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sequence: integer (nullable = true)\n",
      " |-- machine: integer (nullable = true)\n",
      " |-- PID: integer (nullable = true)\n",
      " |-- MINFLT: integer (nullable = true)\n",
      " |-- MAJFLT: integer (nullable = true)\n",
      " |-- VSTEXT: integer (nullable = true)\n",
      " |-- VSIZE: double (nullable = true)\n",
      " |-- RSIZE: double (nullable = true)\n",
      " |-- VGROW: double (nullable = true)\n",
      " |-- RGROW: double (nullable = true)\n",
      " |-- MEM: integer (nullable = true)\n",
      " |-- CMD: string (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      " |-- CMD_PID: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory_df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Persist the transformed streaming data in parquet format for both process and memory (5%)\n",
    "####    - The process data should be stored in “process.parquet” in the same folder of your notebook, and the memory data should be stored in “memory.parquet” in the same folder of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into parquet files the unsuccessful requests partitioned by status code\n",
    "process_query_file_sink = process_df_formatted.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"process.parquet\")\\\n",
    "        .option(\"checkpointLocation\", \"process.parquet/checkpoint_process\")\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the file_sink query\n",
    "process_query_file_sink.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into parquet files the unsuccessful requests partitioned by status code\n",
    "memory_query_file_sink = memory_df_formatted.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"memory.parquet\")\\\n",
    "        .option(\"checkpointLocation\", \"memory.parquet/checkpoint_memory\")\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the file_sink query\n",
    "memory_query_file_sink.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load the machine learning models given, and use the models to predict whether each process or memory streaming record is an attack event, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the process model given to us \n",
    "process_model = PipelineModel.load(\"process_pipeline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict whether each process streaming record is an attack event\n",
    "process_predictions = process_model.transform(process_df_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_predictions \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the memory model given to us\n",
    "memory_model = PipelineModel.load(\"memory_pipeline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict whether each memory streaming record is an attack event\n",
    "memory_predictions = memory_model.transform(memory_df_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_predictions \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using the prediction result, and monitor the data following the requirements below\n",
    " ###   a. If any program in one machine is predicted as an attack in EITHER process or memory activity prediction, it could be a false alarm or a potential attack. Keep track of the approximate count of such events in every 2-min window for each machine for process and memory, respectively, and write the stream into Spark Memory sink using complete mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the attack events\n",
    "process_attacks = process_predictions.filter(process_predictions.prediction == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_attacks \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://stackoverflow.com/questions/44033037/adding-constant-value-column-to-spark-dataframe/44033401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 4\n",
    "machine_4_filtered = process_attacks.filter(F.col('machine') == \"4\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "process_machine4 = machine_4_filtered.groupBy(window(machine_4_filtered.event_time, \"120 seconds\"),machine_4_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_machine4 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 5\n",
    "machine_5_filtered = process_attacks.filter(F.col('machine') == \"5\")\n",
    "process_machine5 = machine_5_filtered.groupBy(window(machine_5_filtered.event_time, \"120 seconds\"),machine_5_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_machine5 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 6\n",
    "machine_6_filtered = process_attacks.filter(F.col('machine') == \"6\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "process_machine6 = machine_6_filtered.groupBy(window(machine_6_filtered.event_time, \"120 seconds\"),machine_6_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_machine6 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 7\n",
    "machine_7_filtered = process_attacks.filter(F.col('machine') == \"7\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "process_machine7 = machine_7_filtered.groupBy(window(machine_7_filtered.event_time, \"120 seconds\"),machine_7_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_machine7 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 8\n",
    "machine_8_filtered = process_attacks.filter(F.col('machine') == \"8\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "process_machine8 = machine_8_filtered.groupBy(window(machine_8_filtered.event_time, \"120 seconds\"),machine_8_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = process_machine8 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the attack events\n",
    "memory_attacks = memory_predictions.filter(memory_predictions.prediction == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_attacks \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://stackoverflow.com/questions/44033037/adding-constant-value-column-to-spark-dataframe/44033401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 4\n",
    "machine_4_filtered = memory_attacks.filter(F.col('machine') == \"4\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "memory_machine4 = machine_4_filtered.groupBy(window(machine_4_filtered.event_time, \"120 seconds\"),machine_4_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_machine4 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 5\n",
    "machine_5_filtered = memory_attacks.filter(F.col('machine') == \"5\")\n",
    "memory_machine5 = machine_5_filtered.groupBy(window(machine_5_filtered.event_time, \"120 seconds\"),machine_5_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_machine5 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 6\n",
    "machine_6_filtered = memory_attacks.filter(F.col('machine') == \"6\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "memory_machine6 = machine_6_filtered.groupBy(window(machine_6_filtered.event_time, \"120 seconds\"),machine_6_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_machine6 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 7\n",
    "machine_7_filtered = memory_attacks.filter(F.col('machine') == \"7\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "memory_machine7 = machine_7_filtered.groupBy(window(machine_7_filtered.event_time, \"120 seconds\"),machine_7_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_machine7 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter attacks for machine no. 8\n",
    "machine_8_filtered = memory_attacks.filter(F.col('machine') == \"8\")\n",
    "#aggregated result including the machine ID, the time window, and the counts is presented\n",
    "memory_machine8 = machine_8_filtered.groupBy(window(machine_8_filtered.event_time, \"120 seconds\"),machine_8_filtered.prediction) \\\n",
    "                                .count()\\\n",
    "                                .select(\"window\",\"count\").withColumn(\"machineID\", lit(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = memory_machine8 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. If a program in one machine, having the same “CMD” and “PID” in both process and memory streaming data, is predicted as an attack in BOTH process and memory activity prediction, then this is considered as an attack event. Find the streaming events fulfilling the criteria, create a new column to record the processing time 8 and persist them in parquet.\n",
    "#### - Note the program with the same “CMD” and “PID” might not be generated at the exact same event time. If the difference between the event times in process and memory is less than 30 seconds and the program fulfills the criteria of matching “CMD” and “PID”, then you should include them for the above checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the attack events\n",
    "process_attacks = process_predictions.filter(process_predictions.prediction == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the attack events\n",
    "memory_attacks = memory_predictions.filter(memory_predictions.prediction == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_memory_df = memory_attacks.selectExpr(\"CAST(sequence AS STRING) AS key_memory\",\n",
    "                                                \"CAST(machine AS STRING) AS machine_memory\",\n",
    "                                                \"CAST(CMD AS STRING) AS CMD_memory\", \n",
    "                                                \"CAST(PID AS STRING) AS PID_memory\",\n",
    "                                                \"CAST(prediction AS STRING) AS prediction_memory\", \n",
    "                                                \"CAST(CMD_PID AS STRING) AS CMD_PID_memory\", \n",
    "                                                \"CAST(event_time AS timestamp) AS event_time_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_process_df = process_attacks.selectExpr(\"CAST(sequence AS STRING) AS key_process\", \n",
    "                                                  \"CAST(machine AS STRING) AS machine_process\", \n",
    "                                                  \"CAST(CMD AS STRING) AS CMD_process\", \n",
    "                                                  \"CAST(PID AS STRING) AS PID_process\",\n",
    "                                                  \"CAST(prediction AS STRING) AS prediction_process\", \n",
    "                                                  \"CAST(CMD_PID AS STRING) AS CMD_PID_process\", \n",
    "                                                  \"CAST(event_time AS timestamp) AS event_time_process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the dataframes according to the sequence and filter the records where CMD and PID is same for process and memory\n",
    "joined_df = predicted_memory_df.join(predicted_process_df,expr(\"\"\"key_memory == key_process\"\"\"),\"inner\")\\\n",
    "                .filter(\"machine_memory == machine_process AND CMD_process == CMD_memory AND PID_process == PID_process\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new column to store the difference between the event time for process and memory activity\n",
    "joined_df2 = joined_df.withColumn('processing_time', abs(joined_df['event_time_memory'].cast(\"long\") - joined_df[\"event_time_process\"].cast(\"long\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key_memory: string (nullable = true)\n",
      " |-- machine_memory: string (nullable = true)\n",
      " |-- CMD_memory: string (nullable = true)\n",
      " |-- PID_memory: string (nullable = true)\n",
      " |-- prediction_memory: string (nullable = false)\n",
      " |-- CMD_PID_memory: string (nullable = true)\n",
      " |-- event_time_memory: timestamp (nullable = false)\n",
      " |-- key_process: string (nullable = true)\n",
      " |-- machine_process: string (nullable = true)\n",
      " |-- CMD_process: string (nullable = true)\n",
      " |-- PID_process: string (nullable = true)\n",
      " |-- prediction_process: string (nullable = false)\n",
      " |-- CMD_PID_process: string (nullable = true)\n",
      " |-- event_time_process: timestamp (nullable = false)\n",
      " |-- processing_time: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter records with processing time less than 30 seconds\n",
    "joined_df3 = joined_df2.filter(\"processing_time < 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start running the query \n",
    "query = joined_df3 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"Append\")\\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into parquet files \n",
    "process_memory_attack_parquet = joined_df3.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"process_memory_attack.parquet\")\\\n",
    "        .option(\"checkpointLocation\", \"process_memory_attack.parquet/checkpoint\")\\\n",
    "        .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the file_sink query\n",
    "process_memory_attack_parquet.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
